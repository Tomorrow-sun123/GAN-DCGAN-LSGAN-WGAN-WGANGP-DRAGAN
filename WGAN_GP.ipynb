{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics setting\n",
    "g_loss_metrics = tf.metrics.Mean(name='g_loss')\n",
    "d_loss_metrics = tf.metrics.Mean(name='d_loss')\n",
    "total_loss_metrics = tf.metrics.Mean(name='total_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper_parameters\n",
    "ITERATION = 1000\n",
    "Z_DIM = 100\n",
    "BATCH_SIZE = 512\n",
    "BUFFER_SIZE = 60000\n",
    "G_LR = 0.0004\n",
    "D_LR = 0.0004\n",
    "GP_WEIGHT = 10.0\n",
    "IMAGE_SHAPE = (28,28,1)\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_z = tf.random.normal([16,Z_DIM])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_z(batch_size,z_dim):\n",
    "    return tf.random.uniform([batch_size,z_dim],minval = -1,maxval = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define discriminator\n",
    "def make_discriminator(input_shape):\n",
    "    return tf.keras.Sequential([\n",
    "        layers.Conv2D(64,5,strides=2,padding='same',input_shape=input_shape),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        layers.Conv2D(128,5,strides=2,padding='same'),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = make_discriminator(IMAGE_SHAPE)\n",
    "#D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define generator\n",
    "def make_generator(input_shape):\n",
    "    return tf.keras.Sequential([\n",
    "        layers.Dense(7*7*256,use_bias=False,input_shape=input_shape),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "        \n",
    "        layers.Reshape((7,7,256)),\n",
    "        \n",
    "        layers.Conv2DTranspose(128,5,strides=1,padding='same',use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "        \n",
    "        layers.Conv2DTranspose(64,5,strides=2,padding='same',use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "        \n",
    "        layers.Conv2DTranspose(1,5,strides=2,padding='same',use_bias=False,activation='tanh')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = make_generator((Z_DIM,))\n",
    "#G.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wassertein Loss\n",
    "def get_loss_fn():\n",
    "    def d_loss_fn(real_logits,fake_logits):\n",
    "        return tf.reduce_mean(fake_logits) - tf.reduce_mean(real_logits)\n",
    "    \n",
    "    def g_loss_fn(fake_logits):\n",
    "        return -tf.reduce_mean(fake_logits)\n",
    "    \n",
    "    return d_loss_fn,g_loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Penalty(GP)\n",
    "def gradient_penalty(generator,real_images,fake_images):\n",
    "    real_images = tf.cast(real_images,tf.float32)\n",
    "    fake_images = tf.cast(fake_images,tf.float32)\n",
    "    alpha = tf.random.uniform([BATCH_SIZE,1,1,1],0.,1.)\n",
    "    diff = fake_images - real_images\n",
    "    inter = real_images + (alpha * diff)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(inter)\n",
    "        prediction = generator(inter)\n",
    "    gradients = tape.gradient(prediction,[inter])[0]\n",
    "    slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients),axis=[1,2,3]))\n",
    "    return tf.reduce_mean((slopes - 1.) **2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data load & preprocessing\n",
    "(train_x,__),(_,_) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "train_x = train_x[...,tf.newaxis].astype(\"float32\")\n",
    "train_x = (train_x - 127.5) / 127.5\n",
    "train_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices(train_x)\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE,drop_remainder=True)\n",
    "    .repeat()\n",
    ")\n",
    "\n",
    "train_ds_1 = (\n",
    "    tf.data.Dataset.from_tensor_slices(train_x)\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE,drop_remainder=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer\n",
    "g_optim = tf.keras.optimizers.Adam(G_LR,beta_1 = 0.5,beta_2 = 0.999)\n",
    "d_optim = tf.keras.optimizers.Adam(D_LR,beta_1 = 0.5,beta_2 = 0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function\n",
    "d_loss_fn,g_loss_fn = get_loss_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(real_images):\n",
    "    z = get_random_z(BATCH_SIZE,Z_DIM)\n",
    "    with tf.GradientTape() as d_tape,tf.GradientTape() as g_tape:\n",
    "        fake_images = G(z,training = True)\n",
    "        \n",
    "        fake_logits = D(fake_images,training = True)\n",
    "        real_logits = D(real_images,training = True)\n",
    "        \n",
    "        d_loss = d_loss_fn(real_logits,fake_logits)\n",
    "        g_loss = g_loss_fn(fake_logits)\n",
    "        \n",
    "        gp = gradient_penalty(partial(D,training=True),real_images,fake_images)\n",
    "        \n",
    "        d_loss = d_loss + gp * GP_WEIGHT\n",
    "    d_gradients = d_tape.gradient(d_loss,D.trainable_variables)\n",
    "    g_gradients = g_tape.gradient(g_loss,G.trainable_variables)\n",
    "    \n",
    "    d_optim.apply_gradients(zip(d_gradients,D.trainable_variables))\n",
    "    g_optim.apply_gradients(zip(g_gradients,G.trainable_variables))\n",
    "    \n",
    "    return g_loss,d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义生成器可视化函数\n",
    "def generate_plot_image(generator_model,test_noise):\n",
    "    pre_images = generator_model(test_noise,training=False)\n",
    "    #因为定义了seed为16张图片\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    for i in range(pre_images.shape[0]):\n",
    "        plt.subplot(4,4,i+1)\n",
    "        plt.imshow((pre_images[i,:,:,0]+1)/2,cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loop\n",
    "def train(ds,log_freq = 20):\n",
    "    ds = iter(ds)\n",
    "    for step in range(ITERATION):\n",
    "        images = next(ds)\n",
    "        g_loss,d_loss = train_step(images)\n",
    "        \n",
    "        g_loss_metrics(g_loss)\n",
    "        d_loss_metrics(d_loss)\n",
    "        total_loss_metrics(g_loss + d_loss)\n",
    "        if step % log_freq == 0:\n",
    "            template = '[{}/{}] D_loss={:.5f} G_loss={:.5f} Total_loss={:.5f}'\n",
    "            print(template.format(step,ITERATION,d_loss_metrics.result(),\n",
    "                                 g_loss_metrics.result(),total_loss_metrics.result()))\n",
    "            g_loss_metrics.reset_states()\n",
    "            d_loss_metrics.reset_states()\n",
    "            total_loss_metrics.reset_states()\n",
    "            generate_plot_image(G,test_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loop\n",
    "def train_1(ds,epochs):\n",
    "    for epoch in range(epochs):\n",
    "        i = 0\n",
    "        for image_batch in ds:\n",
    "            g_loss,d_loss = train_step(image_batch)\n",
    "            print(\"epoch = {}; i={}\".format(epoch+1,i))\n",
    "            i+= 1\n",
    "\n",
    "        g_loss_metrics(g_loss)\n",
    "        d_loss_metrics(d_loss)\n",
    "        total_loss_metrics(g_loss + d_loss)\n",
    "       \n",
    "        template = '[{}/{}] D_loss={:.5f} G_loss={:.5f} Total_loss={:.5f}'\n",
    "        print(template.format(epoch+1,epochs,d_loss_metrics.result(),\n",
    "                             g_loss_metrics.result(),total_loss_metrics.result()))\n",
    "        g_loss_metrics.reset_states()\n",
    "        d_loss_metrics.reset_states()\n",
    "        total_loss_metrics.reset_states()\n",
    "        generate_plot_image(G,test_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_1(train_ds_1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
